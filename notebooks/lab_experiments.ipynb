{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This notebook is used for experimentation to find the best reccomendations. Depending on the case, not all cells are ran.",
   "id": "f62defa331a3e8bd"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-04T16:12:43.613020Z",
     "start_time": "2025-12-04T16:12:43.565239Z"
    }
   },
   "source": [
    "# Enable auto-reloading so you can edit .py files without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "# Add the project root to path so we can import 'src'\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.data_loader import DataLoader\n",
    "from src.models import CollaborativeRecommender, ContentRecommender, HybridRecommender\n",
    "from src.utils import tune_alpha, get_tuning_sample, generate_kaggle_submission, tune_half_life\n",
    "from src.evaluation import ModelEvaluator\n",
    "\n",
    "# Intercepts calls to NearestNeighbors, SVD, and k-means and routes them through Intel's optimized oneDAL library.\n",
    "# This often results in a 10x-100x speedup on Intel chips without changing the code logic.\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Data",
   "id": "f56258f09ac94f1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:12:47.279382Z",
     "start_time": "2025-12-04T16:12:46.638068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Initialize Loader\n",
    "loader = DataLoader(base_path='../data')\n",
    "\n",
    "# 2. Get Chronological Split (Train/Test)\n",
    "# We apply Time Decay (Half-Life = 120 days) for the models that use it\n",
    "train_df, test_df = loader.get_time_split(train_ratio=0.8, half_life_days=120)\n",
    "\n",
    "# 3. Get Content Artifacts (Matrices & Map)\n",
    "tfidf, vectors, item_map = loader.get_content_data()\n",
    "\n",
    "# 4. Get Full Dataset\n",
    "full_df = loader.get_full_data(half_life_days=120)\n",
    "\n",
    "print(\"\\n>>> Data Summary:\")\n",
    "print(f\"   Train Interactions: {len(train_df)}\")\n",
    "print(f\"   Test Interactions:  {len(test_df)}\")\n",
    "print(f\"   Unique Items:       {len(item_map)}\")"
   ],
   "id": "5c7fc2a80b7da006",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading Interactions...\n",
      "   -> Interactions loaded: 87045 rows\n",
      ">>> Splitting Data (First 80% Train)...\n",
      "   -> Applying Time Decay (Half-Life: 120 days)...\n",
      "   -> Train: 66580 | Test: 20465\n",
      "   -> Total: 66580 + 20465 = 87045\n",
      ">>> Loading Content Artifacts...\n",
      "   -> Loaded features for 15291 items.\n",
      ">>> Preparing Full Dataset (Half-Life: 120 days)...\n",
      "   -> Full Data Weighted: 87045 rows\n",
      "\n",
      ">>> Data Summary:\n",
      "   Train Interactions: 66580\n",
      "   Test Interactions:  20465\n",
      "   Unique Items:       15291\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Experimentation",
   "id": "97c43fe8c3338f1f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Collaborative-Based Recommender",
   "id": "964c48ed765b50be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T14:33:21.694625Z",
     "start_time": "2025-12-04T14:33:21.631668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\">>> Building Baseline Models...\")\n",
    "\n",
    "# 1. Collaborative Filtering (Memory-Based)\n",
    "# It automatically detects the 'weight' column in train_df\n",
    "cf_model = CollaborativeRecommender(train_df)\n",
    "print(\">>> Collaborative Model Built.\")"
   ],
   "id": "dba824f32460a35d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Building Baseline Models...\n",
      "   -> Applying TF-IDF to Interaction Matrix...\n",
      ">>> Collaborative Model Built.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T14:33:44.657546Z",
     "start_time": "2025-12-04T14:33:23.121601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n>>> Evaluating: Collaborative Filtering\")\n",
    "all_item_ids = full_df['item_id'].unique()\n",
    "evaluator = ModelEvaluator(train_df, all_item_ids)\n",
    "res_cf= evaluator.evaluate(cf_model, test_df, k=10, model_name=\"Collaborative (TF-IDF)\")\n",
    "\n",
    "print(f\"\\n>>> Results:\")\n",
    "print(f\"   -> Hit Rate @ 10: {res_cf['Hit Rate @ 10']:.4%}\")\n",
    "print(f\"   -> MAP @ 10: {res_cf['MAP @ 10']:.4%}\")\n",
    "print(f\"   -> Novelty: {res_cf['Novelty']:.4%}\")\n",
    "print(f\"   -> Coverage: {res_cf['Coverage']:.4%}\")"
   ],
   "id": "5a9aaed9ef6eed91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Evaluating: Collaborative Filtering\n",
      "   -> Pre-computing Item Popularity for Novelty metrics...\n",
      ">>> Evaluating Collaborative (TF-IDF) on 20465 users...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Eval Collaborative (TF-IDF):   0%|          | 0/20465 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ddeb4f617bf4bdb987f588b54f28a80"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Results:\n",
      "   -> Hit Rate @ 10: 27.0364%\n",
      "   -> MAP @ 10: 13.8385%\n",
      "   -> Novelty: 1309.2480%\n",
      "   -> Coverage: 85.5384%\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tuning Alphas Hyperparameters",
   "id": "6fc1767f5034649"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Content-Based Recommender",
   "id": "d151f7928caef69a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T14:48:58.757373Z",
     "start_time": "2025-12-04T14:33:44.672248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Content-Based Filtering\n",
    "# We need to tune alpha (TF-IDF vs MiniLM)\n",
    "print(\"\\n>>> Tuning Content Alpha... (Sample of user)\")\n",
    "tuning_df = get_tuning_sample(test_df, n_users=1000)\n",
    "best_content_alpha = tune_alpha(\n",
    "    model=ContentRecommender(train_df, tfidf, vectors, item_map),\n",
    "    test_df=tuning_df,\n",
    "    param_name='alpha'\n",
    ")"
   ],
   "id": "9c331548b3ad9fe8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Tuning Content Alpha... (Sample of user)\n",
      "   -> Sampling Strategy: Selected 1000 Users\n",
      "   -> Original Rows: 20465 | Sampled Rows: 2496\n",
      ">>> Tuning 'alpha' on 2496 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha=0.0: 100%|██████████| 2496/2496 [02:54<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.0] Hit Rate: 20.59294872%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha=0.2: 100%|██████████| 2496/2496 [02:56<00:00, 14.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.2] Hit Rate: 21.11378205%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha=0.5: 100%|██████████| 2496/2496 [03:10<00:00, 13.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.5] Hit Rate: 20.99358974%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha=0.8: 100%|██████████| 2496/2496 [03:08<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.8] Hit Rate: 19.75160256%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha=1.0: 100%|██████████| 2496/2496 [03:04<00:00, 13.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [1.0] Hit Rate: 17.90865385%\n",
      "\n",
      ">>> Best alpha: 0.2 (Hit Rate: 21.11378205%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T14:58:09.304825Z",
     "start_time": "2025-12-04T14:58:09.273505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate optimized model\n",
    "content_model = ContentRecommender(train_df, tfidf, vectors, item_map)\n",
    "print(f\">>> Content Model Built (Alpha: {best_content_alpha})\")"
   ],
   "id": "5fb97a906383536c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Content Model Built (Alpha: 0.2)\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hybrid Content-Collaboration Recommender",
   "id": "99a431aef57c292"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T14:58:39.020891Z",
     "start_time": "2025-12-04T14:58:38.991341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate the Hybrid\n",
    "# We pass the best_content_alpha we just found so the Content engine inside is optimized.\n",
    "hybrid_model = HybridRecommender(\n",
    "    cf_model,\n",
    "    content_model,\n",
    "    content_alpha=best_content_alpha\n",
    ")"
   ],
   "id": "12a66159796712dd",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T15:20:40.500856Z",
     "start_time": "2025-12-04T14:58:46.594313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We use the same 'tuning_df' sample to keep it fast\n",
    "print(\">>> Tuning Hybrid Alpha (CF vs Content)...\")\n",
    "\n",
    "best_hybrid_alpha = tune_alpha(\n",
    "    model=hybrid_model,\n",
    "    test_df=tuning_df,  # Use the same sample for consistency/speed\n",
    "    param_name='hybrid_alpha',\n",
    "    values=[0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]\n",
    ")\n",
    "\n",
    "print(f\"\\n>>> Optimal Hybrid Configuration:\")\n",
    "print(f\"   -> Content Internal Alpha: {best_content_alpha}\")\n",
    "print(f\"   -> Hybrid Balance Alpha:   {best_hybrid_alpha}\")\n",
    "\n",
    "if best_hybrid_alpha > 0.5:\n",
    "    print(\"   -> Interpretation: The model leans towards Collaborative Filtering (Social Signals).\")\n",
    "elif best_hybrid_alpha < 0.5:\n",
    "    print(\"   -> Interpretation: The model leans towards Content Matching (Metadata).\")\n",
    "else:\n",
    "    print(\"   -> Interpretation: A perfect 50/50 balance.\")"
   ],
   "id": "5514e2d074c5119c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Tuning Hybrid Alpha (CF vs Content)...\n",
      ">>> Tuning 'hybrid_alpha' on 2496 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=0.0: 100%|██████████| 2496/2496 [03:03<00:00, 13.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.0] Hit Rate: 21.27403846%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=0.2: 100%|██████████| 2496/2496 [03:04<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.2] Hit Rate: 22.87660256%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=0.4: 100%|██████████| 2496/2496 [03:08<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.4] Hit Rate: 24.43910256%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=0.5: 100%|██████████| 2496/2496 [03:03<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.5] Hit Rate: 24.83974359%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=0.6: 100%|██████████| 2496/2496 [03:21<00:00, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.6] Hit Rate: 25.16025641%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=0.8: 100%|██████████| 2496/2496 [03:11<00:00, 13.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.8] Hit Rate: 25.28044872%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=1.0: 100%|██████████| 2496/2496 [03:01<00:00, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [1.0] Hit Rate: 25.40064103%\n",
      "\n",
      ">>> Best hybrid_alpha: 1.0 (Hit Rate: 25.40064103%)\n",
      "\n",
      ">>> Optimal Hybrid Configuration:\n",
      "   -> Content Internal Alpha: 0.2\n",
      "   -> Hybrid Balance Alpha:   1.0\n",
      "   -> Interpretation: The model leans towards Collaborative Filtering (Social Signals).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T15:25:03.458601Z",
     "start_time": "2025-12-04T15:25:03.428858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# best_content_alpha = 0.5\n",
    "# best_hybrid_alpha = 0.6\n",
    "\n",
    "final_alpha_config = {\n",
    "    \"best_content_alpha\": best_content_alpha,\n",
    "    \"best_hybrid_alpha\": best_hybrid_alpha,\n",
    "}\n",
    "\n",
    "joblib.dump(final_alpha_config, '../data/artifacts/best_params_hl180.pkl')\n",
    "print(\">>> Alphas Hyperparameters Saved:\")\n",
    "print(final_alpha_config)"
   ],
   "id": "6ae3a1aac095abb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Alphas Hyperparameters Saved:\n",
      "{'best_content_alpha': 0.2, 'best_hybrid_alpha': 1.0}\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### (Tuning Half-Life)",
   "id": "44b8891924eea863"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T12:08:57.347189Z",
     "start_time": "2025-12-04T12:08:57.249338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "saved_config = joblib.load('../data/artifacts/best_params.pkl')\n",
    "best_content_alpha = saved_config.get('best_content_alpha', 0.5)\n",
    "best_hybrid_alpha = saved_config.get('best_hybrid_alpha', 0.6)\n",
    "print(f\">>> Loaded Saved Alphas:\")\n",
    "print(f\"   -> Content Alpha: {best_content_alpha}\")\n",
    "print(f\"   -> Hybrid Alpha:  {best_hybrid_alpha}\")"
   ],
   "id": "179ecf0cc10d5584",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loaded Saved Alphas:\n",
      "   -> Content Alpha: 0.5\n",
      "   -> Hybrid Alpha:  0.6\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T13:01:23.682047Z",
     "start_time": "2025-12-04T12:08:58.494304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_item_ids = full_df['item_id'].unique()\n",
    "evaluator = ModelEvaluator(train_df, all_item_ids)\n",
    "\n",
    "best_half_life = tune_half_life(\n",
    "    loader=loader,\n",
    "    test_df=test_df,\n",
    "    item_tfidf=tfidf,\n",
    "    item_minilm=vectors,\n",
    "    item_map=item_map,\n",
    "    evaluator=evaluator,\n",
    "    best_c_alpha=best_content_alpha,\n",
    "    best_h_alpha=best_hybrid_alpha,\n",
    "    k=10\n",
    ")\n",
    "saved_config['best_half_life'] = best_half_life"
   ],
   "id": "f7cb09641fea762b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Pre-computing Item Popularity for Novelty metrics...\n",
      ">>> Tuning Half-Life (Data Decay) with Checkpointing...\n",
      "   -> Found existing checkpoint with 4 results.\n",
      "\n",
      "--- [Skipping] Half-Life = 30 days (Found: 25.9956%) ---\n",
      "\n",
      "--- [Skipping] Half-Life = 60 days (Found: 26.7579%) ---\n",
      "\n",
      "--- [Skipping] Half-Life = 90 days (Found: 27.0462%) ---\n",
      "\n",
      "--- [Skipping] Half-Life = 120 days (Found: 27.2221%) ---\n",
      "\n",
      "--- Testing Half-Life = 180 days ---\n",
      ">>> Splitting Data (First 80% Train)...\n",
      "   -> Applying Time Decay (Half-Life: 180 days)...\n",
      "   -> Train: 66580 | Test: 20465\n",
      "   -> Total: 66580 + 20465 = 87045\n",
      "   -> Applying TF-IDF to Interaction Matrix...\n",
      ">>> Evaluating Hybrid (HL=180) on 20465 users...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Eval Hybrid (HL=180):   0%|          | 0/20465 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e78dc98fe0a14b73a6029796cd605feb"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Hit Rate: 27.2563% at HL=180 days\n",
      "   -> Saved Checkpoint: ../data/artifacts/half_life_results.pkl\n",
      "\n",
      "--- Testing Half-Life = 365 days ---\n",
      ">>> Splitting Data (First 80% Train)...\n",
      "   -> Applying Time Decay (Half-Life: 365 days)...\n",
      "   -> Train: 66580 | Test: 20465\n",
      "   -> Total: 66580 + 20465 = 87045\n",
      "   -> Applying TF-IDF to Interaction Matrix...\n",
      ">>> Evaluating Hybrid (HL=365) on 20465 users...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Eval Hybrid (HL=365):   0%|          | 0/20465 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "522888c338374c02a801d045ccf78a22"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Hit Rate: 27.0266% at HL=365 days\n",
      "   -> Saved Checkpoint: ../data/artifacts/half_life_results.pkl\n",
      "\n",
      ">>> Evaluation Summary:\n",
      "   -> Hit Rate: 25.9956% at HL=30 days\n",
      "   -> Hit Rate: 26.7579% at HL=60 days\n",
      "   -> Hit Rate: 27.0462% at HL=90 days\n",
      "   -> Hit Rate: 27.2221% at HL=120 days\n",
      "   -> Hit Rate: 27.2563% at HL=180 days\n",
      "   -> Hit Rate: 27.0266% at HL=365 days\n",
      "\n",
      ">>> Best Half-Life: 180 days\n",
      "   -> Hit Rate: 27.2563%\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T14:28:12.778254Z",
     "start_time": "2025-12-04T14:28:12.744277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "joblib.dump(saved_config, '../data/artifacts/best_params.pkl')\n",
    "print(\">>> Half-Life + Alphas Hyperparameters Saved:\")\n",
    "print(saved_config)"
   ],
   "id": "fdcea0490fab6bd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Half-Life + Alphas Hyperparameters Saved:\n",
      "{'best_content_alpha': 0.5, 'best_hybrid_alpha': 0.6, 'best_half_life': 180}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We tuned our models with 'half_life'= 120 but now we know that the best half_life value is actually 180 so we will re-tune our hyperparameters by running previous cells again with best_half_life",
   "id": "ca8f0321321842a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FINAL : Retraining on full dataset",
   "id": "415f90c864512733"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:56:32.711828Z",
     "start_time": "2025-12-04T16:56:32.668608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_config = joblib.load('../data/artifacts/winning_best_params.pkl')\n",
    "print(final_config)\n",
    "best_content_alpha = final_config.get('best_content_alpha', 0.5)\n",
    "best_hybrid_alpha = final_config.get('best_hybrid_alpha', 0.6)\n",
    "print(f\">>> Loaded Saved Alphas:\")\n",
    "print(f\"   -> Content Alpha: {best_content_alpha}\")\n",
    "print(f\"   -> Hybrid Alpha:  {best_hybrid_alpha}\")"
   ],
   "id": "4ee6ebe792066a4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_content_alpha': 0.5, 'best_hybrid_alpha': 0.6, 'best_half_life': 120}\n",
      ">>> Loaded Saved Alphas:\n",
      "   -> Content Alpha: 0.5\n",
      "   -> Hybrid Alpha:  0.6\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:56:34.212904Z",
     "start_time": "2025-12-04T16:56:34.139772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n>>> BUILDING FINAL PRODUCTION MODELS...\")\n",
    "\n",
    "#Train Collaborative Model (Full Data)\n",
    "cf_full = CollaborativeRecommender(full_df)\n",
    "print(\"   -> Collaborative Model Retrained.\")\n",
    "\n",
    "# Train Content Model (Full Data)\n",
    "# Reuses the artifacts (tfidf, vectors) which are already full catalog\n",
    "content_full = ContentRecommender(\n",
    "    full_df,\n",
    "    tfidf,\n",
    "    vectors,\n",
    "    item_map\n",
    ")\n",
    "print(\"   -> Content Model Retrained.\")"
   ],
   "id": "86c4af1396391cf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> BUILDING FINAL PRODUCTION MODELS...\n",
      "   -> Applying TF-IDF to Interaction Matrix...\n",
      "   -> Collaborative Model Retrained.\n",
      "   -> Content Model Retrained.\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:56:36.638245Z",
     "start_time": "2025-12-04T16:56:36.593082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hybrid Model\n",
    "# We pass the optimized alpha we just saved\n",
    "hybrid_full = HybridRecommender(\n",
    "    cf_full,\n",
    "    content_full,\n",
    "    content_alpha=best_content_alpha\n",
    ")\n",
    "\n",
    "print(f\"   -> Hybrid Model Assembled (Content Alpha: {best_content_alpha})\")\n",
    "print(\"\\n>>> Final Model Ready for Submission Generation.\")"
   ],
   "id": "80f569b586e37e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Hybrid Model Assembled (Content Alpha: 0.5)\n",
      "\n",
      ">>> Final Model Ready for Submission Generation.\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "target_users = full_df['user_id'].unique()\n",
    "submission = generate_kaggle_submission(\n",
    "    model=hybrid_full,\n",
    "    target_user_ids=target_users,\n",
    "    k=10,\n",
    "    hybrid_alpha=best_hybrid_alpha,\n",
    "    pop_weight=0.2)"
   ],
   "id": "41ad6670f742d33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:58:42.206876700Z",
     "start_time": "2025-12-04T16:41:45.913762Z"
    }
   },
   "cell_type": "code",
   "source": "submission",
   "id": "e7bc8abb1f6b6b09",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      user_id                                     recommendation\n",
       "0           0                  23 16 13 19 24 21 22 611 13261 17\n",
       "1           1            37 36 38 10715 39 8999 9926 33 611 2553\n",
       "2           2         58 53 14990 92 3055 91 8999 10715 75 14991\n",
       "3           3       132 169 149 14107 171 2553 167 611 165 12087\n",
       "4           4          195 205 203 207 11366 248 206 200 204 202\n",
       "...       ...                                                ...\n",
       "7833     7833    7760 7322 975 5838 611 667 7127 10967 8498 4921\n",
       "7834     7834   7128 1367 8999 3055 13891 92 10715 14991 36 7121\n",
       "7835     7835     3055 6791 4820 9310 10715 45 53 8999 9719 3019\n",
       "7836     7836  3471 14550 14557 3816 3055 611 10715 3470 8999...\n",
       "7837     7837  88 2191 2209 10715 11676 4901 3475 2156 4426 8973\n",
       "\n",
       "[7838 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23 16 13 19 24 21 22 611 13261 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37 36 38 10715 39 8999 9926 33 611 2553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>58 53 14990 92 3055 91 8999 10715 75 14991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>132 169 149 14107 171 2553 167 611 165 12087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>195 205 203 207 11366 248 206 200 204 202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>7833</td>\n",
       "      <td>7760 7322 975 5838 611 667 7127 10967 8498 4921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>7834</td>\n",
       "      <td>7128 1367 8999 3055 13891 92 10715 14991 36 7121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>7835</td>\n",
       "      <td>3055 6791 4820 9310 10715 45 53 8999 9719 3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>7836</td>\n",
       "      <td>3471 14550 14557 3816 3055 611 10715 3470 8999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>7837</td>\n",
       "      <td>88 2191 2209 10715 11676 4901 3475 2156 4426 8973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7838 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save",
   "id": "b97506b650f8a5aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:41:52.276772Z",
     "start_time": "2025-12-04T16:41:52.191350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save submission\n",
    "submission.to_csv('../submissions/submission_final.csv', index=False)"
   ],
   "id": "9434329361e53454",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:41:56.263542Z",
     "start_time": "2025-12-04T16:41:53.768642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save all the models\n",
    "joblib.dump(cf_full, '../models/cf_model.pkl')\n",
    "joblib.dump(content_full, '../models/content_model.pkl')\n",
    "joblib.dump(hybrid_full, '../models/hybrid_model.pkl')"
   ],
   "id": "3ab3945643a578ed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/hybrid_model.pkl']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Final Evaluation",
   "id": "3c5cabf691ad8a54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T17:28:41.353720Z",
     "start_time": "2025-12-04T17:02:52.249548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_model = joblib.load('../models/hybrid_model.pkl')\n",
    "\n",
    "all_item_ids = full_df['item_id'].unique()\n",
    "evaluator = ModelEvaluator(train_df, all_item_ids)\n",
    "res_cf= evaluator.evaluate(final_model, test_df, k=10, model_name=\"Hybrid\")\n",
    "\n",
    "print(f\"\\n>>> Results:\")\n",
    "print(f\"   -> Hit Rate @ 10: {res_cf['Hit Rate @ 10']:.4%}\")\n",
    "print(f\"   -> MAP @ 10: {res_cf['MAP @ 10']:.4%}\")\n",
    "print(f\"   -> Novelty: {res_cf['Novelty']:.4%}\")\n",
    "print(f\"   -> Coverage: {res_cf['Coverage']:.4%}\")"
   ],
   "id": "36fe5d1caa5d1c9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Pre-computing Item Popularity for Novelty metrics...\n",
      ">>> Evaluating Hybrid on 20465 users...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Eval Hybrid:   0%|          | 0/20465 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a142cc705514abd8c9d488491463397"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Results:\n",
      "   -> Hit Rate @ 10: 75.8417%\n",
      "   -> MAP @ 10: 42.3133%\n",
      "   -> Novelty: 1375.0498%\n",
      "   -> Coverage: 89.1058%\n"
     ]
    }
   ],
   "execution_count": 82
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
