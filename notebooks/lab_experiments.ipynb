{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-03T08:10:28.714474Z",
     "start_time": "2025-12-03T08:10:26.927349Z"
    }
   },
   "source": [
    "# Enable auto-reloading so you can edit .py files without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the project root to path so we can import 'src'\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.data_loader import DataLoader\n",
    "from src.models import CollaborativeRecommender, ContentRecommender, HybridRecommender, SVDRecommender\n",
    "from src.utils import tune_alpha, tune_svd, get_tuning_sample, generate_kaggle_submission\n",
    "from src.evaluation import ModelEvaluator\n",
    "\n",
    "# Intercepts calls to NearestNeighbors, SVD, and k-means and routes them through Intel's optimized oneDAL library.\n",
    "# This often results in a 10x-100x speedup on Intel chips without changing the code logic.\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T08:10:32.032989Z",
     "start_time": "2025-12-03T08:10:31.410393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Initialize Loader\n",
    "loader = DataLoader(base_path='../data')\n",
    "\n",
    "# 2. Get Chronological Split (Train/Test)\n",
    "# We apply Time Decay (Half-Life = 120 days) for the models that use it\n",
    "train_df, test_df = loader.get_time_split(train_ratio=0.8, half_life_days=120)\n",
    "\n",
    "# 3. Get Content Artifacts (Matrices & Map)\n",
    "tfidf, vectors, item_map = loader.get_content_data()\n",
    "\n",
    "# 4. Get Full Dataset\n",
    "full_df = loader.get_full_data(half_life_days=120)\n",
    "\n",
    "print(\"\\n>>> Data Summary:\")\n",
    "print(f\"   Train Interactions: {len(train_df)}\")\n",
    "print(f\"   Test Interactions:  {len(test_df)}\")\n",
    "print(f\"   Unique Items:       {len(item_map)}\")"
   ],
   "id": "5c7fc2a80b7da006",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading Interactions...\n",
      "   -> Interactions loaded: 87045 rows\n",
      ">>> Splitting Data (First 80% Train)...\n",
      "   -> Applying Time Decay (Half-Life: 120 days)...\n",
      "   -> Train: 66580 | Test: 20465\n",
      "   -> Total: 66580 + 20465 = 87045\n",
      ">>> Loading Content Artifacts...\n",
      "   -> Loaded features for 15291 items.\n",
      ">>> Preparing Full Dataset (Half-Life: 120 days)...\n",
      "   -> Full Data Weighted: 87045 rows\n",
      "\n",
      ">>> Data Summary:\n",
      "   Train Interactions: 66580\n",
      "   Test Interactions:  20465\n",
      "   Unique Items:       15291\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Collaborative-Based Recommender",
   "id": "964c48ed765b50be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "TODO ADD EXPLANATION\n",
    "\n",
    "No hyperparameters to tune"
   ],
   "id": "62653140322156a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T08:10:51.915907Z",
     "start_time": "2025-12-03T08:10:51.815528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\">>> Building Baseline Models...\")\n",
    "\n",
    "# 1. Collaborative Filtering (Memory-Based)\n",
    "# It automatically detects the 'weight' column in train_df\n",
    "cf_model = CollaborativeRecommender(train_df)\n",
    "print(\">>> Collaborative Model Built.\")"
   ],
   "id": "dba824f32460a35d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Building Baseline Models...\n",
      "   -> Applying TF-IDF to Interaction Matrix...\n",
      ">>> Collaborative Model Built.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T08:11:40.682009Z",
     "start_time": "2025-12-03T08:11:22.979937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n>>> EVALUATING: Collaborative Filtering\")\n",
    "all_item_ids = full_df['item_id'].unique()\n",
    "evaluator = ModelEvaluator(train_df, all_item_ids)\n",
    "res_cf= evaluator.evaluate(cf_model, test_df, k=10, model_name=\"Collaborative (TF-IDF)\")\n",
    "\n",
    "print(f\"   -> Score: {res_cf['Hit Rate @ 10']:.4%}\")"
   ],
   "id": "5a9aaed9ef6eed91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> EVALUATING: Collaborative Filtering\n",
      "   -> Pre-computing Item Popularity for Novelty metrics...\n",
      ">>> Evaluating Collaborative (TF-IDF) on 20465 users...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Eval Collaborative (TF-IDF):   0%|          | 0/20465 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "528659a1cb534a84958cad4371a9d012"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Score: 3.9384%\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Content-Based Recommender",
   "id": "d151f7928caef69a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T08:06:54.259790Z",
     "start_time": "2025-12-03T08:03:53.093283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Content-Based Filtering\n",
    "# We need to tune alpha (TF-IDF vs MiniLM)\n",
    "print(\"\\n>>> Tuning Content Alpha... (Sample of user)\")\n",
    "tuning_df = get_tuning_sample(test_df, n_users=1000)\n",
    "best_content_alpha = tune_alpha(\n",
    "    model=ContentRecommender(train_df, tfidf, vectors, item_map),\n",
    "    test_df=tuning_df,\n",
    "    param_name='alpha'\n",
    ")"
   ],
   "id": "9c331548b3ad9fe8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Tuning Content Alpha... (Sample of user)\n",
      "   -> Sampling Strategy: Selected 1000 Users\n",
      "   -> Original Rows: 20465 | Sampled Rows: 2496\n",
      ">>> Tuning 'alpha' on 2496 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha=0.0:  42%|████▏     | 1044/2496 [02:58<04:08,  5.84it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[25]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m>>> Tuning Content Alpha... (Sample of user)\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      4\u001B[39m tuning_df = get_tuning_sample(test_df, n_users=\u001B[32m1000\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m best_content_alpha = \u001B[43mtune_alpha\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mContentRecommender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtfidf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvectors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem_map\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtest_df\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtuning_df\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mparam_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43malpha\u001B[39;49m\u001B[33;43m'\u001B[39;49m\n\u001B[32m      9\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DSML_Kaggle_Competition\\src\\utils.py:62\u001B[39m, in \u001B[36mtune_alpha\u001B[39m\u001B[34m(model, test_df, param_name, k, values)\u001B[39m\n\u001B[32m     57\u001B[39m target = row[\u001B[33m'\u001B[39m\u001B[33mitem_id\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     59\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     60\u001B[39m     \u001B[38;5;66;03m# Call recommend with dynamic parameter\u001B[39;00m\n\u001B[32m     61\u001B[39m     \u001B[38;5;66;03m# e.g., model.recommend(user_id, top_k=10, alpha=0.2)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m62\u001B[39m     recs = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrecommend\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[43m=\u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     64\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m target \u001B[38;5;129;01min\u001B[39;00m recs:\n\u001B[32m     65\u001B[39m         hits += \u001B[32m1\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DSML_Kaggle_Competition\\src\\models.py:112\u001B[39m, in \u001B[36mrecommend\u001B[39m\u001B[34m(self, user_id, top_k, alpha, remove_seen)\u001B[39m\n\u001B[32m    108\u001B[39m     self.idx_to_item = {v: k for k, v in item_to_row_idx.items()}\n\u001B[32m    109\u001B[39m     self.popular_items = interactions_df['item_id'].value_counts().head(20).index.tolist()\n\u001B[32m    111\u001B[39m def recommend(self, user_id, top_k=10, alpha=0.5, remove_seen=True):\n\u001B[32m--> \u001B[39m\u001B[32m112\u001B[39m     # 1. Get History\n\u001B[32m    113\u001B[39m     user_data = self.interactions_df[self.interactions_df['user_id'] == user_id]\n\u001B[32m    115\u001B[39m     if len(user_data) == 0:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    212\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    213\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    214\u001B[39m         skip_parameter_validation=(\n\u001B[32m    215\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    216\u001B[39m         )\n\u001B[32m    217\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m218\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    220\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    223\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    224\u001B[39m     msg = re.sub(\n\u001B[32m    225\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    226\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    227\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    228\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1728\u001B[39m, in \u001B[36mcosine_similarity\u001B[39m\u001B[34m(X, Y, dense_output)\u001B[39m\n\u001B[32m   1675\u001B[39m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[32m   1676\u001B[39m     {\n\u001B[32m   1677\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mX\u001B[39m\u001B[33m\"\u001B[39m: [\u001B[33m\"\u001B[39m\u001B[33marray-like\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33msparse matrix\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m   (...)\u001B[39m\u001B[32m   1682\u001B[39m )\n\u001B[32m   1683\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcosine_similarity\u001B[39m(X, Y=\u001B[38;5;28;01mNone\u001B[39;00m, dense_output=\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[32m   1684\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001B[39;00m\n\u001B[32m   1685\u001B[39m \n\u001B[32m   1686\u001B[39m \u001B[33;03m    Cosine similarity, or the cosine kernel, computes similarity as the\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1726\u001B[39m \u001B[33;03m           [0.577, 0.816]])\u001B[39;00m\n\u001B[32m   1727\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1728\u001B[39m     X, Y = \u001B[43mcheck_pairwise_arrays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1730\u001B[39m     X_normalized = normalize(X, copy=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m   1731\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m Y:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:209\u001B[39m, in \u001B[36mcheck_pairwise_arrays\u001B[39m\u001B[34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_all_finite, ensure_2d, copy)\u001B[39m\n\u001B[32m    199\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    200\u001B[39m     X = check_array(\n\u001B[32m    201\u001B[39m         X,\n\u001B[32m    202\u001B[39m         accept_sparse=accept_sparse,\n\u001B[32m   (...)\u001B[39m\u001B[32m    207\u001B[39m         ensure_2d=ensure_2d,\n\u001B[32m    208\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m209\u001B[39m     Y = \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    210\u001B[39m \u001B[43m        \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    211\u001B[39m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    212\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    213\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    214\u001B[39m \u001B[43m        \u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    215\u001B[39m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    216\u001B[39m \u001B[43m        \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    217\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m precomputed:\n\u001B[32m    220\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m X.shape[\u001B[32m1\u001B[39m] != Y.shape[\u001B[32m0\u001B[39m]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1053\u001B[39m, in \u001B[36mcheck_array\u001B[39m\u001B[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[39m\n\u001B[32m   1051\u001B[39m         array = xp.astype(array, dtype, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1052\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1053\u001B[39m         array = \u001B[43m_asarray_with_order\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m=\u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1054\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[32m   1055\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1056\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m.format(array)\n\u001B[32m   1057\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcomplex_warning\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:757\u001B[39m, in \u001B[36m_asarray_with_order\u001B[39m\u001B[34m(array, dtype, order, copy, xp, device)\u001B[39m\n\u001B[32m    755\u001B[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001B[32m    756\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m757\u001B[39m     array = \u001B[43mnumpy\u001B[49m\u001B[43m.\u001B[49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m=\u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    759\u001B[39m \u001B[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001B[39;00m\n\u001B[32m    760\u001B[39m \u001B[38;5;66;03m# container that is consistent with the input's namespace.\u001B[39;00m\n\u001B[32m    761\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m xp.asarray(array)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T08:12:16.850524Z",
     "start_time": "2025-12-03T08:12:16.765055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate optimized model\n",
    "best_content_alpha = 0.5\n",
    "content_model = ContentRecommender(train_df, tfidf, vectors, item_map)\n",
    "print(f\">>> Content Model Built (Alpha: {best_content_alpha})\")"
   ],
   "id": "5fb97a906383536c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Content Model Built (Alpha: 0.5)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hybrid Content-Collaboration Recommender",
   "id": "99a431aef57c292"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T08:12:21.927226Z",
     "start_time": "2025-12-03T08:12:21.855050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate the Hybrid\n",
    "# We pass the best_content_alpha we just found so the Content engine inside is optimized.\n",
    "hybrid_model = HybridRecommender(\n",
    "    cf_model,\n",
    "    content_model,\n",
    "    content_alpha=best_content_alpha\n",
    ")"
   ],
   "id": "12a66159796712dd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T07:37:44.796034Z",
     "start_time": "2025-12-03T07:15:04.471255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We use the same 'tuning_df' sample to keep it fast\n",
    "print(\">>> Tuning Hybrid Alpha (CF vs Content)...\")\n",
    "\n",
    "best_hybrid_alpha = tune_alpha(\n",
    "    model=hybrid_model,\n",
    "    test_df=tuning_df,  # Use the same sample for consistency/speed\n",
    "    param_name='hybrid_alpha',\n",
    "    values=[0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]\n",
    ")\n",
    "\n",
    "print(f\"\\n>>> Optimal Hybrid Configuration:\")\n",
    "print(f\"   -> Content Internal Alpha: {best_content_alpha}\")\n",
    "print(f\"   -> Hybrid Balance Alpha:   {best_hybrid_alpha}\")\n",
    "\n",
    "if best_hybrid_alpha > 0.5:\n",
    "    print(\"   -> Interpretation: The model leans towards Collaborative Filtering (Social Signals).\")\n",
    "elif best_hybrid_alpha < 0.5:\n",
    "    print(\"   -> Interpretation: The model leans towards Content Matching (Metadata).\")\n",
    "else:\n",
    "    print(\"   -> Interpretation: A perfect 50/50 balance.\")"
   ],
   "id": "5514e2d074c5119c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Tuning Hybrid Alpha (CF vs Content)...\n",
      ">>> Tuning 'hybrid_alpha' on 2496 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=0.0: 100%|██████████| 2496/2496 [03:13<00:00, 12.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.0] Hit Rate: 3.92628205%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=0.2: 100%|██████████| 2496/2496 [03:15<00:00, 12.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.2] Hit Rate: 4.36698718%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=0.4: 100%|██████████| 2496/2496 [03:16<00:00, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.4] Hit Rate: 4.36698718%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=0.5: 100%|██████████| 2496/2496 [03:15<00:00, 12.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.5] Hit Rate: 4.24679487%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=0.6: 100%|██████████| 2496/2496 [03:17<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.6] Hit Rate: 4.12660256%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=0.8: 100%|██████████| 2496/2496 [03:23<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [0.8] Hit Rate: 3.72596154%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid_alpha=1.0: 100%|██████████| 2496/2496 [02:57<00:00, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [1.0] Hit Rate: 2.76442308%\n",
      "\n",
      ">>> Best hybrid_alpha: 0.2 (Hit Rate: 4.36698718%)\n",
      "\n",
      ">>> Optimal Hybrid Configuration:\n",
      "   -> Content Internal Alpha: 0.5\n",
      "   -> Hybrid Balance Alpha:   0.2\n",
      "   -> Interpretation: The model leans towards Content Matching (Metadata).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save parameters",
   "id": "10ad54bb623faf5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T08:13:27.275916Z",
     "start_time": "2025-12-03T08:13:27.197833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_content_alpha = 0.5\n",
    "best_hybrid_alpha = 0.2\n",
    "\n",
    "final_config = {\n",
    "    \"best_content_alpha\": best_content_alpha,\n",
    "    \"best_hybrid_alpha\": best_hybrid_alpha,\n",
    "}\n",
    "\n",
    "joblib.dump(final_config, '../data/artifacts/best_params.pkl')\n",
    "print(\">>> Hyperparameters Saved:\")\n",
    "print(final_config)"
   ],
   "id": "6ae3a1aac095abb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Hyperparameters Saved:\n",
      "{'best_content_alpha': 0.5, 'best_hybrid_alpha': 0.2}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Retraining on full dataset",
   "id": "415f90c864512733"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T08:13:29.874902Z",
     "start_time": "2025-12-03T08:13:29.720478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n>>> BUILDING FINAL PRODUCTION MODELS...\")\n",
    "\n",
    "#Train Collaborative Model (Full Data)\n",
    "cf_full = CollaborativeRecommender(full_df)\n",
    "print(\"   -> Collaborative Model Retrained.\")\n",
    "\n",
    "# Train Content Model (Full Data)\n",
    "# Reuses the artifacts (tfidf, vectors) which are already full catalog\n",
    "content_full = ContentRecommender(\n",
    "    full_df,\n",
    "    tfidf,\n",
    "    vectors,\n",
    "    item_map\n",
    ")\n",
    "print(\"   -> Content Model Retrained.\")"
   ],
   "id": "86c4af1396391cf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> BUILDING FINAL PRODUCTION MODELS...\n",
      "   -> Applying TF-IDF to Interaction Matrix...\n",
      "   -> Collaborative Model Retrained.\n",
      "   -> Content Model Retrained.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T08:13:31.162008Z",
     "start_time": "2025-12-03T08:13:31.078573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hybrid Model\n",
    "# We pass the optimized alpha we just saved\n",
    "hybrid_full = HybridRecommender(\n",
    "    cf_full,\n",
    "    content_full,\n",
    "    content_alpha=final_config['best_content_alpha']\n",
    ")\n",
    "\n",
    "print(f\"   -> Hybrid Model Assembled (Content Alpha: {final_config['best_content_alpha']})\")\n",
    "print(\"\\n>>> Final Model Ready for Submission Generation.\")"
   ],
   "id": "80f569b586e37e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Hybrid Model Assembled (Content Alpha: 0.5)\n",
      "\n",
      ">>> Final Model Ready for Submission Generation.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T08:44:16.780842Z",
     "start_time": "2025-12-03T08:16:00.149764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_users = full_df['user_id'].unique()\n",
    "sumbmission = generate_kaggle_submission(hybrid_full, target_users, 10, final_config['best_hybrid_alpha'])"
   ],
   "id": "41ad6670f742d33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Generating predictions for 7838 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Submission: 100%|██████████| 7838/7838 [28:16<00:00,  4.62it/s]  \n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T08:44:17.171344Z",
     "start_time": "2025-12-03T08:44:16.983643Z"
    }
   },
   "cell_type": "code",
   "source": "sumbmission",
   "id": "e7bc8abb1f6b6b09",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      user_id                                     recommendation\n",
       "0           0  9759 13261 4512 8096 611 6890 13307 8404 6433 ...\n",
       "1           1  3222 9926 2553 27 1573 15023 1367 4024 2489 13434\n",
       "2           2  8999 14990 3055 14991 8474 3062 10715 14824 80...\n",
       "3           3   1436 14107 794 2553 10372 12087 611 2309 82 2145\n",
       "4           4  248 7995 3505 6231 4712 1506 3127 13765 11366 ...\n",
       "...       ...                                                ...\n",
       "7833     7833  5838 10967 4921 667 7127 14778 7306 8498 2350 ...\n",
       "7834     7834        8999 92 36 14991 7121 3062 3055 114 7178 54\n",
       "7835     7835     45 9310 9719 12813 92 8369 11045 53 12811 3019\n",
       "7836     7836  14557 3816 3470 3062 14552 14991 7325 611 3469...\n",
       "7837     7837  3475 11676 4901 4861 8973 14107 2156 7716 3299...\n",
       "\n",
       "[7838 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9759 13261 4512 8096 611 6890 13307 8404 6433 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3222 9926 2553 27 1573 15023 1367 4024 2489 13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8999 14990 3055 14991 8474 3062 10715 14824 80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1436 14107 794 2553 10372 12087 611 2309 82 2145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>248 7995 3505 6231 4712 1506 3127 13765 11366 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>7833</td>\n",
       "      <td>5838 10967 4921 667 7127 14778 7306 8498 2350 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>7834</td>\n",
       "      <td>8999 92 36 14991 7121 3062 3055 114 7178 54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>7835</td>\n",
       "      <td>45 9310 9719 12813 92 8369 11045 53 12811 3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>7836</td>\n",
       "      <td>14557 3816 3470 3062 14552 14991 7325 611 3469...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>7837</td>\n",
       "      <td>3475 11676 4901 4861 8973 14107 2156 7716 3299...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7838 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save",
   "id": "b97506b650f8a5aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T08:44:22.405190Z",
     "start_time": "2025-12-03T08:44:22.321778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save submission\n",
    "sumbmission.to_csv('../submissions/submission.csv', index=False)"
   ],
   "id": "9434329361e53454",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T07:47:30.291838Z",
     "start_time": "2025-12-03T07:47:28.629167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save all the models\n",
    "joblib.dump(cf_full, '../models/cf_model.pkl')\n",
    "joblib.dump(content_full, '../models/content_model.pkl')\n",
    "joblib.dump(hybrid_full, '../models/hybrid_model.pkl')"
   ],
   "id": "3ab3945643a578ed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/hybrid_model.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
